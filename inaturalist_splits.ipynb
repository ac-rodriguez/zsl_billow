{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eee527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c743f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'species_list.csv'\n",
    "\n",
    "df_species = pd.read_csv(filename, index_col=0)\n",
    "    \n",
    "print(df_species.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afa6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de4e16",
   "metadata": {},
   "source": [
    "## iNaturalist 2017 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "DATAPATH = '/scratch/data/iNaturalist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25645393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = DATAPATH+'/2017/train_val2017/train2017.json'\n",
    "\n",
    "with open(train_file) as json_file:\n",
    "    train_annotations = json.load(json_file)\n",
    "\n",
    "val_file = DATAPATH+'/2017/train_val2017/val2017.json'\n",
    "\n",
    "with open(val_file) as json_file:\n",
    "    val_annotations = json.load(json_file)\n",
    "\n",
    "test_file = DATAPATH+'/2017/test2017/test2017.json'\n",
    "\n",
    "with open(test_file) as json_file:\n",
    "    test_annotations = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5281ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_inat = [x['name'] for x in train_annotations['categories'] if x['supercategory'] == 'Aves']\n",
    "\n",
    "df1 = df_species[df_species.sci_name.isin(names_inat)]\n",
    "print(df1.shape)\n",
    "sci_names_inat = list(df1.sci_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7cbe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = [x for x  in  train_annotations['images'] if x['file_name'].split('/')[2] in sci_names_inat]\n",
    "\n",
    "val_subset = [x for x  in  val_annotations['images'] if x['file_name'].split('/')[2] in sci_names_inat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e73af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train  complete {} subset {}'.format(len(train_annotations['images']), len(train_subset)))\n",
    "\n",
    "print('Val  complete {} subset {}'.format(len(val_annotations['images']), len(val_subset)))\n",
    "\n",
    "print('Test  complete {} subset'.format(len(test_annotations['images'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88096445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = [x['file_name'][:-4] for x in train_subset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c3450",
   "metadata": {},
   "source": [
    "### Create class splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "results = []\n",
    "for order,  group in df1.groupby('order'):\n",
    "    for family, group1 in group.groupby('family_name'):\n",
    "        for genus, group2 in group1.groupby('genus'):\n",
    "            for species, group3 in group2.groupby('sci_name'):\n",
    "                results.append({'order':order,'n_families':group['family_name'].drop_duplicates().shape[0],\n",
    "                                'family':family,'n_genus':group1['genus'].drop_duplicates().shape[0],\n",
    "                                'genus':genus,'n_species':group2['sci_name'].drop_duplicates().shape[0],\n",
    "                                'sci_name':species,'is_train':np.random.random() > 0.2\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(results)\n",
    "print(df2.shape)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a7c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (df2['n_families'] > 1) & (df2['n_genus'] > 1) & (df2['n_species'] > 1)\n",
    "\n",
    "df2.loc[~index, 'is_train'] = False\n",
    "print(df2.is_train.mean())\n",
    "\n",
    "df3 = df2[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.shape)\n",
    "\n",
    "# df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab7fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df3[df3['is_train']]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df2[~df2['is_train']]\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2393c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1hop = df_val.genus.isin(df_train.genus)\n",
    "\n",
    "df_val_1hop = df_val[index_1hop]\n",
    "\n",
    "df_val_1hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2hop = df_val.family.isin(df_train.family) & ~df_val.genus.isin(df_train.genus)\n",
    "\n",
    "df_val_2hop = df_val[index_2hop]\n",
    "\n",
    "df_val_2hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3hop = df_val.order.isin(df_train.order) & ~df_val.family.isin(df_train.family)\n",
    "\n",
    "df_val_3hop = df_val[index_3hop]\n",
    "\n",
    "df_val_3hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a66b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4hop = ~df_val.order.isin(df_train.order)\n",
    "\n",
    "df_val_4hop = df_val[index_4hop]\n",
    "\n",
    "df_val_4hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sets = {'train':df_train,\n",
    "            'val_seen':df_train,\n",
    "            'val allhop':df_val,\n",
    "            'val 1hop':df_val_1hop,\n",
    "            'val 2hop':df_val_2hop,\n",
    "            'val 3hop':df_val_3hop,\n",
    "            'val 4hop':df_val_4hop,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39f6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_overwrite = False \n",
    "import pickle\n",
    "\n",
    "file = DATAPATH+'/2017/zsl_splits/all_splits.pickle'\n",
    "if is_overwrite:\n",
    "    with open(file, 'wb') as handle:\n",
    "        pickle.dump(val_sets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(file, 'rb') as handle:\n",
    "        val_sets = pickle.load(handle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8788839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = val_sets['train']\n",
    "\n",
    "list_out = []\n",
    "for key, val in val_sets.items():\n",
    "    \n",
    "    list_ = list(val['sci_name'])\n",
    "    \n",
    "    dset_zsl = [x for x  in  train_subset if x['file_name'].split('/')[2] in list_]\n",
    "    n1 = len(dset_zsl)\n",
    "    # else:\n",
    "    dset_zsl = [x for x  in  val_subset if x['file_name'].split('/')[2] in list_]\n",
    "    n2 = len(dset_zsl)\n",
    "    n3 = n1 if key == 'train' else n2\n",
    "        \n",
    "    # print( f' {key} n sci_name = {val.shape[0]} , n_images = {n1 + n2}')\n",
    "\n",
    "    list_out.append({'Set':key,\n",
    "        #  'n1':n1,'n2':n2,'n1+n2':n1+n2,\n",
    "        'n_samples':n3})\n",
    "    for level in ['order','family','genus','sci_name']:\n",
    "        index_ = val[level].drop_duplicates().isin(df_train[level])\n",
    "        list_out[-1][level+'_train'] = index_.sum()\n",
    "        list_out[-1][level] = index_.shape[0]\n",
    "        # print(f'\\t {level} in train {index_.sum()} ({index_.mean():.1%})')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_17 = pd.DataFrame(list_out).set_index('Set')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def use_f_2(x):\n",
    "    return f'{x:,.0f}'\n",
    "\n",
    "df_summary_17[['n_samples','sci_name']].to_latex(\n",
    "        # 'tables/inat17_splits.tex',\n",
    "        formatters=[use_f_2,use_f_2]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0016483",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = DATAPATH+'/2017/zsl_splits/'\n",
    "\n",
    "is_overwrite = False\n",
    "if is_overwrite:\n",
    "    df_train['sci_name'].to_csv(save_dir + \"seen_classes.txt\", index = False,header=False)\n",
    "    df_val['sci_name'].to_csv(save_dir + \"unseen_allhop_classes.txt\", index = False,header=False)\n",
    "    df_val_1hop['sci_name'].to_csv(save_dir + \"unseen_1hop_classes.txt\", index = False,header=False)\n",
    "    df_val_2hop['sci_name'].to_csv(save_dir + \"unseen_2hop_classes.txt\", index = False,header=False)\n",
    "    df_val_3hop['sci_name'].to_csv(save_dir + \"unseen_3hop_classes.txt\", index = False,header=False)\n",
    "    df_val_4hop['sci_name'].to_csv(save_dir + \"unseen_4hop_classes.txt\", index = False,header=False)\n",
    "\n",
    "    df2['sci_name'].to_csv(save_dir + \"all_classes.txt\", index = False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceedcaac",
   "metadata": {},
   "source": [
    "## iNaturalist 2021 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = DATAPATH+'/2021/train.json'\n",
    "\n",
    "with open(train_file) as json_file:\n",
    "    train_annotations = json.load(json_file)\n",
    "\n",
    "train_mini_file = DATAPATH+'/2021/train_mini.json'\n",
    "\n",
    "with open(train_mini_file) as json_file:\n",
    "    train_mini_annotations = json.load(json_file)\n",
    "\n",
    "val_file = DATAPATH+'/2021/val.json'\n",
    "\n",
    "with open(val_file) as json_file:\n",
    "    val_annotations = json.load(json_file)\n",
    "\n",
    "\n",
    "test_file = DATAPATH+'/2021/public_test.json'\n",
    "\n",
    "with open(test_file) as json_file:\n",
    "    test_annotations = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dee816",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_inat = [x['name'] for x in val_annotations['categories'] if x['supercategory'] == 'Birds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_val = [x['image_dir_name'] for x in val_annotations['categories'] if x['supercategory'] == 'Birds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36507910",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_inat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dfe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subseting to only species that have samples in Billow\n",
    "df_illustrations = pd.read_csv('illustrations_list.txt', index_col=0)\n",
    "\n",
    "df_merged = df_illustrations.reset_index().set_index('sci_name').join(df_species.set_index('sci_name'), how='left').reset_index().set_index('index').sort_index()\n",
    "# \n",
    "df_count = df_merged.groupby('sci_name')['sample'].count()\n",
    "df_count = df_count[df_count > 0]\n",
    "df2 = df_count[df_count.index.isin(names_inat)]\n",
    "print(df2.shape)\n",
    "\n",
    "sci_names_inat = list(df2.index)\n",
    "\n",
    "df1 = df_species[df_species.sci_name.isin(sci_names_inat)]\n",
    "print(df1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sciname = lambda x: ' '.join(x.split('/')[1].split('_')[-2:])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = [x for x  in  train_annotations['images'] if get_sciname(x['file_name']) in sci_names_inat]\n",
    "\n",
    "train_mini_subset = [x for x  in  train_mini_annotations['images'] if get_sciname(x['file_name']) in sci_names_inat]\n",
    "\n",
    "val_subset = [x for x  in  val_annotations['images'] if get_sciname(x['file_name']) in sci_names_inat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train  complete {} subset {}'.format(len(train_annotations['images']), len(train_subset)))\n",
    "print('Train-mini  complete {} subset {}'.format(len(train_mini_annotations['images']), len(train_mini_subset)))\n",
    "print('Val  complete {} subset {}'.format(len(val_annotations['images']), len(val_subset)))\n",
    "print('Test  complete {}'.format(len(test_annotations['images'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792c59e",
   "metadata": {},
   "source": [
    "### Create class splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "results = []\n",
    "for order,  group in df1.groupby('order'):\n",
    "    for family, group1 in group.groupby('family_name'):\n",
    "        for genus, group2 in group1.groupby('genus'):\n",
    "            for species, group3 in group2.groupby('sci_name'):\n",
    "                results.append({'order':order,'n_families':group['family_name'].drop_duplicates().shape[0],\n",
    "                                'family':family,'n_genus':group1['genus'].drop_duplicates().shape[0],\n",
    "                                'genus':genus,'n_species':group2['sci_name'].drop_duplicates().shape[0],\n",
    "                                'sci_name':species,'is_train':np.random.random() > 0.2\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c28488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(results)\n",
    "print(df2.shape)\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6941c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (df2['n_families'] > 1) & (df2['n_genus'] > 1) & (df2['n_species'] > 1)\n",
    "\n",
    "df2.loc[~index, 'is_train'] = False\n",
    "print(df2.is_train.mean())\n",
    "\n",
    "df3 = df2[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.shape)\n",
    "\n",
    "# df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df3[df3['is_train']]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df2[~df2['is_train']]\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28603305",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_1hop = df_val.genus.isin(df_train.genus)\n",
    "\n",
    "df_val_1hop = df_val[index_1hop]\n",
    "\n",
    "df_val_1hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8836c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2hop = df_val.family.isin(df_train.family) & ~df_val.genus.isin(df_train.genus)\n",
    "\n",
    "df_val_2hop = df_val[index_2hop]\n",
    "\n",
    "df_val_2hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_3hop = df_val.order.isin(df_train.order) & ~df_val.family.isin(df_train.family)\n",
    "\n",
    "df_val_3hop = df_val[index_3hop]\n",
    "\n",
    "df_val_3hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33679778",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_4hop = ~df_val.order.isin(df_train.order)\n",
    "\n",
    "df_val_4hop = df_val[index_4hop]\n",
    "\n",
    "df_val_4hop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sets = {'train':df_train,\n",
    "            'val_seen':df_train,\n",
    "            'val allhop':df_val,\n",
    "            'val 1hop':df_val_1hop,\n",
    "            'val 2hop':df_val_2hop,\n",
    "            'val 3hop':df_val_3hop,\n",
    "            'val 4hop':df_val_4hop,}\n",
    "\n",
    "\n",
    "is_overwrite = False\n",
    "import pickle\n",
    "\n",
    "file = DATAPATH+'/2021/zsl_splits/all_splits.pickle'\n",
    "if is_overwrite:\n",
    "    with open(file, 'wb') as handle:\n",
    "        pickle.dump(val_sets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(file, 'rb') as handle:\n",
    "        val_sets = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bfd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train = val_sets['train']\n",
    "\n",
    "list_out = []\n",
    "for key, val in val_sets.items():\n",
    "    \n",
    "    list_ = list(val['sci_name'])\n",
    "    \n",
    "    dset_zsl = [x for x  in  train_subset if get_sciname(x['file_name']) in list_]\n",
    "    n1 = len(dset_zsl)\n",
    "    # else:\n",
    "    dset_zsl = [x for x  in  val_subset if get_sciname(x['file_name']) in list_]\n",
    "    n2 = len(dset_zsl)\n",
    "    n3 = n1 if key == 'train' else n2\n",
    "        \n",
    "    # print( f' {key} n sci_name = {val.shape[0]} , n_images = {n1 + n2}')\n",
    "\n",
    "    list_out.append({'Set':key,\n",
    "        #  'n1':n1,'n2':n2,'n1+n2':n1+n2,\n",
    "        'n_samples':n3})\n",
    "    for level in ['order','family','genus','sci_name']:\n",
    "        index_ = val[level].drop_duplicates().isin(df_train[level])\n",
    "        list_out[-1][level+'_train'] = index_.sum()\n",
    "        list_out[-1][level] = index_.shape[0]\n",
    "        # print(f'\\t {level} in train {index_.sum()} ({index_.mean():.1%})')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb95401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_21 = pd.DataFrame(list_out).set_index('Set')\n",
    "def use_f_2(x):\n",
    "    return f'{x:,.0f}'\n",
    "\n",
    "# df.to_latex(formatters=[None, use_f_2, use_f_2])\n",
    "\n",
    "df_summary_21[['n_samples','sci_name']].to_latex(\n",
    "        # 'tables/inat21_splits.tex',\n",
    "        # float_format=\"{:0.2f}\".format\n",
    "        formatters=[use_f_2,use_f_2]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed922314",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = DATAPATH+'/2021/zsl_splits/'\n",
    "\n",
    "is_overwrite = False\n",
    "if is_overwrite:\n",
    "    df_train['sci_name'].to_csv(save_dir + \"seen_classes.txt\", index = False,header=False)\n",
    "    df_val['sci_name'].to_csv(save_dir + \"unseen_allhop_classes.txt\", index = False,header=False)\n",
    "    df_val_1hop['sci_name'].to_csv(save_dir + \"unseen_1hop_classes.txt\", index = False,header=False)\n",
    "    df_val_2hop['sci_name'].to_csv(save_dir + \"unseen_2hop_classes.txt\", index = False,header=False)\n",
    "    df_val_3hop['sci_name'].to_csv(save_dir + \"unseen_3hop_classes.txt\", index = False,header=False)\n",
    "    df_val_4hop['sci_name'].to_csv(save_dir + \"unseen_4hop_classes.txt\", index = False,header=False)\n",
    "    df2['sci_name'].to_csv(save_dir + \"all_classes.txt\", index = False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb592d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee30d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary_17['Year'] = 2017\n",
    "df_summary_21['Year'] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0388228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = pd.concat((df_summary_17,df_summary_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.index, df_summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d1f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_summary.reset_index().set_index(['Set','Year'])[['n_samples','sci_name']].unstack(1)[[('n_samples', 2017),\n",
    "            ( 'sci_name', 2017),\n",
    "            ('n_samples', 2021),\n",
    "            ( 'sci_name', 2021)]].swaplevel(axis=1)\n",
    "df_out.stack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.stack().T.to_latex(\n",
    "        # 'tables/inat_splits.T.tex',\n",
    "        # formatters=4*[use_f_2]\n",
    "        )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
